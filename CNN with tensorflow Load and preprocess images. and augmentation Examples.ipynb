{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 50\n",
    "img_height = 50\n",
    "batch_size = 32"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset loading Using dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###   Using dataset_from_directory\n",
    "\n",
    "ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'PetImages/',\n",
    "    labels='inferred',\n",
    "    label_mode =\"categorical\", #int, binary\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height,img_width),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.1,\n",
    "    subset=\"training\",    \n",
    ")\n",
    "\n",
    "ds_validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'PetImages/',\n",
    "    labels='inferred',\n",
    "    label_mode =\"categorical\", #int, binary\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height,img_width),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.1,\n",
    "    subset=\"validation\",    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation using functions\n",
    "\n",
    "def normalize_img(image, label):\n",
    "    \"\"\"Normalizes images\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "def augment(image,label):\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_contrast(image, lower=0.1, upper=0.2)\n",
    "    image = tf.image.random_flip_left_right(image)  # 50%\n",
    "    image = tf.image.random_flip_up_down(image) #%50%\n",
    "    \n",
    "    return image, label\n",
    "\n",
    " ## Data augmentation function calls\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE =32\n",
    "\n",
    "ds_train = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.map(augment,num_parallel_calls=AUTOTUNE)\n",
    "ds_train = ds_train.batch(BATCH_SIZE)\n",
    "ds_train = ds_train.prefetch(AUTOTUNE)\n",
    "\n",
    "\n",
    "ds_validation = ds_validation.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_validation = ds_validation.batch(BATCH_SIZE)\n",
    "ds_validation = ds_validation.prefetch(AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential ([\n",
    "    layers.Input((50,50,1)),\n",
    "    layers.Conv2D(32,(3,3),padding = 'same'),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    \n",
    "    layers.Conv2D(16,(3,3),padding = 'same'),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(100, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation ='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(3e-4),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(ds_train, epochs=5, verbose=2)\n",
    "model.evaluate(ds_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(ds_train, epochs=5, verbose=2)\n",
    "model.evaluate(ds_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TF >= 2.3.0 (Sequential)\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        #layers.experimental.preprocessing.Resizing(height=32, width=32,),\n",
    "        layers.experimental.preprocessing.RandomFlip(mode=\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomContrast(factor=0.1,),\n",
    "    ]\n",
    ")\n",
    "\n",
    "## data_augmentation function calls when model is building\n",
    "model = keras.Sequential ([\n",
    "    layers.Input((50,50,1)),\n",
    "    data_augmentation,\n",
    "    layers.Conv2D(32,(3,3),padding = 'same'),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    \n",
    "    layers.Conv2D(16,(3,3),padding = 'same'),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(100, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation ='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(3e-4),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(ds_train, epochs=5, verbose=2)\n",
    "model.evaluate(ds_validation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset loading ImageDataGenerator and flow_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=5,\n",
    "    zoom_range=(0.95, 0.95),\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    data_format=\"channels_last\",\n",
    "    validation_split=0.0,\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    \"PetImages/\",\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"sparse\",\n",
    "    shuffle=True,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential ([\n",
    "    layers.Input((50,50,1)),\n",
    "    layers.Conv2D(32,(3,3),padding = 'same'),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    \n",
    "    layers.Conv2D(16,(3,3),padding = 'same'),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(100, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation ='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 - 19s - loss: 0.6976 - accuracy: 0.5263 - 19s/epoch - 741ms/step\n",
      "Epoch 2/10\n",
      "25/25 - 17s - loss: 0.6941 - accuracy: 0.4737 - 17s/epoch - 673ms/step\n",
      "Epoch 3/10\n",
      "25/25 - 16s - loss: 0.6935 - accuracy: 0.5063 - 16s/epoch - 624ms/step\n",
      "Epoch 4/10\n",
      "25/25 - 17s - loss: 0.6954 - accuracy: 0.5088 - 17s/epoch - 675ms/step\n",
      "Epoch 5/10\n",
      "25/25 - 15s - loss: 0.6944 - accuracy: 0.5000 - 15s/epoch - 600ms/step\n",
      "Epoch 6/10\n",
      "25/25 - 15s - loss: 0.6925 - accuracy: 0.5322 - 15s/epoch - 597ms/step\n",
      "Epoch 7/10\n",
      "25/25 - 14s - loss: 0.6936 - accuracy: 0.4938 - 14s/epoch - 578ms/step\n",
      "Epoch 8/10\n",
      "25/25 - 14s - loss: 0.6894 - accuracy: 0.5450 - 14s/epoch - 579ms/step\n",
      "Epoch 9/10\n",
      "25/25 - 13s - loss: 0.6848 - accuracy: 0.5600 - 13s/epoch - 522ms/step\n",
      "Epoch 10/10\n",
      "25/25 - 13s - loss: 0.6879 - accuracy: 0.5400 - 13s/epoch - 531ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e20316f880>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=[keras.losses.SparseCategoricalCrossentropy(from_logits=True),],\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=25,\n",
    "    verbose=2,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
